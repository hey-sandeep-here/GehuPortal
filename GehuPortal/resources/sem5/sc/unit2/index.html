<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Unit 2</title>
    <link rel="stylesheet" href="../../../../public/style.css">
    <link rel="icon" href="../../../../public/logo/favicon_io/favicon.ico">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body class="bg-c">
    <div id="mySidepanel" class="sidepanel">
        <a href="javascript:void(0)" class="closebtn" onclick="closeNav()">×</a>
        <a href="../index.html" class="home">back</a>
        <div class="fix-column-links">
            <a href="#" class="link"></a>
            <div class="botbut">
                <a href="" class="link">Next Topic &rarr;</a>
                <a href="" class="link">&larr; Previous Topic</a>
            </div>
        </div>
    </div>
    <div id="navbar" class="grad">
        <div>
            <div class="openbtn" onclick="openNav()">
                <div id="nav-icon1" for="nav-menu1">
                    <span></span>
                    <span></span>
                    <span></span>
                </div>
            </div>
        </div>
        <div>
            <h2>Unit 2</h2>
        </div>
    </div>
    <div class="content-box">
        <div class="wh">
            <h2>Feed Forward Network</h2>
            <p>Feedforward neural networks (FNNs) are a class of artificial neural networks (ANNs) where the information
                moves in one direction—forward—from the input nodes, through the hidden layers, and finally to the
                output nodes. There are no cycles or loops in the network, which is why it's called "feedforward." This
                network structure is one of the simplest and most commonly used models in machine learning and deep
                learning for a variety of tasks such as classification, regression, and pattern recognition.</p>
            <p><strong>Key Components:</strong></p>
            <ol>
                <li>Input Layer: This layer receives the input data. The number of neurons in this layer corresponds to
                    the number of input features in the dataset.</li>
                <li>Hidden Layer(s): These layers are where computations take place using weights and activation
                    functions. A feedforward network can have one or more hidden layers, making it either a shallow or
                    deep neural network. The hidden layers are responsible for extracting and transforming features from
                    the input data.</li>
                <li>Output Layer: The final layer produces the network's output, which could be a class label (in
                    classification tasks) or a continuous value (in regression tasks). The number of neurons in the
                    output layer depends on the task, such as the number of classes for classification.</li>
                <li>Weights and Biases: Weights determine the influence of a particular input on the output, while
                    biases adjust the output along with the weighted sum of inputs, helping the network fit the data
                    better.</li>
                <li>Activation Functions: Activation functions (e.g., sigmoid, ReLU, or tanh) introduce non-linearity
                    into the network, enabling it to learn complex patterns.</li>
            </ol>
            <p><strong>Learning Process:</strong></p>
            <ul>
                <li>The training process of an FNN involves adjusting the weights and biases of the network to minimize
                    the error between the predicted and actual outputs. This is typically done using optimization
                    algorithms such as gradient descent, and the error is measured using a loss function (like mean
                    squared error for regression or cross-entropy for classification).</li>
                <li>Feedforward networks rely on the concept of supervised learning, where they are trained using
                    labeled datasets. During training, the network computes an output, compares it with the actual
                    label, and backpropagates the error through the network to update the weights in such a way that
                    future predictions become more accurate.</li>
            </ul>
            <p><strong>Variants of Feedforward Networks</strong></p>
            <p>There are several extensions of the basic feedforward network model, which enhance its functionality for
                specific tasks. Two popular variants are:</p>
            <ol>
                <li><strong>Back propagation Neural Network (BPN)</strong>: This is an extension of the feedforward
                    network that uses the back propagation algorithm to update the weights during the training process.
                    BPN is one of the most commonly used learning algorithms for feedforward networks, especially for
                    multi-layer perceptrons (MLPs). It minimizes the error by propagating it backward through the
                    network layers.</li>
                <li><strong>Radial Basis Function Network (RBFN)</strong>: RBFN is another variant of the feedforward
                    network, but it uses radial basis functions as activation functions. RBFNs are particularly useful
                    for interpolation problems, classification, and regression tasks. They consist of an input layer, a
                    hidden layer with radial basis function neurons, and an output layer, typically using linear
                    neurons.</li>
            </ol>
            <div class="in">
                <h3>Backpropagation Neural Network (BPN)</h3>
                <ul>
                    <li>It is a standard method for training Artificial Neural Networks (ANNs).</li>
                    <li>
                        BPN is a method of continuously adjusting the weights of the connections in the network to
                        minimize the difference between the actual output and the desired output. This method aims to
                        find the minimum value of the error in the weight space using the delta rule of gradient
                        descent.
                    </li>
                </ul>

                <p><strong>Steps in BPN:</strong></p>
                <ol>
                    <li>Input <strong>x</strong> is introduced to the network through pre-connected paths.</li>
                    <li>Inputs are modeled using randomly assigned weights <strong>w</strong>.</li>
                    <li>Calculate the output of each neuron, propagating from the input layer to the hidden layer, and
                        then to the output layer.</li>
                    <li>Calculate the error at the output layer. The error can be computed as the difference between the
                        actual output and the desired output (i.e., <strong>Error = Actual Output - Desired
                            Output</strong>).</li>
                    <li>
                        The error is then propagated backward, from the output layer to the hidden layer, and then back
                        to the input layer. The weights are adjusted at each layer to reduce the error. This process is
                        repeated iteratively until the error is minimized.
                    </li>
                </ol>
                <p><strong>Confusion?</strong></p>
                <ul>
                    <li>Even though backpropagation involves "going backward," this backward flow occurs only during the
                        training phase. The backpropagation algorithm computes the gradients of the error with respect
                        to each weight in the network by working backward, but this process is purely for adjusting the
                        weights and is not part of the actual inference or data flow during prediction.</li>
                    <li>Thus, during inference or the actual operation of the network (when you're making predictions),
                        the data still flows strictly in the forward direction—from inputs to outputs. This is why
                        networks trained using backpropagation are still considered feedforward networks. The term
                        "feedforward" refers to how information is processed when the network is used for predictions,
                        not how it learns.</li>
                    <li>BPN ko feedforward network ke under isliye include karte hain kyunki backward direction sirf
                        training ke time pe hota hai. Jab hum network ko train karte hain, tab error ko piche ki taraf
                        propagate karke weights adjust karte hain. Lekin jab actual prediction karte hain, yaani jab hum
                        model ko real data dete hain, toh data sirf forward direction mai flow hota hai—input se output
                        tak.
                        <br>
                        Yeh jo term 'feedforward' hai, yeh sirf prediction ke process ke baare mein hai, training ke
                        time pe kya hota hai, usse nahi. Isliye, BPN ko feedforward neural network mana jata hai, kyunki
                        prediction ke waqt data forward hi move karta hai.
                    </li>
                </ul>
                <div class="wh">
                    <p><strong>Example Problem:</strong> Assume that the neurons have a sigmoid activation function,
                        perform a forward pass and a backward pass on the network. Assume that the actual output of y is
                        0.5 and learning rate is 1.</p>
                    <img src="../../images/sc8.jpeg" alt="">
                    <p><strong>Forward Pass</strong>: Compute output for y<sub>3</sub>, y<sub>4</sub> and y<sub>5</sub>.
                    </p>
                    <ul>
                        <li>a<sub>j</sub> = \( \sum_{j} (w_ij * x_i) \)</li>
                        <br>y<sub>j</sub> = f(aj) = <span class="ms">\( f(x) = \frac{1}{1 + e^{-a_j}} \)</span>
                        <li>y<sub>3</sub> = f(a1) = <span class="ms">\( f(a1) = \frac{1}{1 + e^{-a_1}} \)</span>
                            <br>a1 = (w<sub>13</sub> * x<sub>1</sub> ) + (w<sub>23</sub> * x<sub>2</sub>) = 0.755
                            <br>y<sub>3</sub> = f(0.755) = <span class="ms">\( f(a1) = \frac{1}{1 + e^{-0.755}}
                                \)</span> = 0.68

                        </li>
                        <li>y<sub>4</sub> = f(a2) = <span class="ms">\( f(a2) = \frac{1}{1 + e^{-a_2}} \)</span>
                            <br>a2 = (w<sub>14</sub> * x<sub>1</sub> ) + (w<sub>24</sub> * x<sub>2</sub>) = 0.68
                            <br>y<sub>4</sub> = f(0.68) = <span class="ms">\( f(a1) = \frac{1}{1 + e^{-0.68}} \)</span>
                            = 0.6637

                        </li>
                        <li>y<sub>5</sub> = f(a3) = <span class="ms">\( f(a3) = \frac{1}{1 + e^{-a_1}} \)</span>
                            <br>a3 = (w<sub>35</sub> * y<sub>3</sub> ) + (w<sub>45</sub> * y<sub>4</sub>) = 0.801
                            <br>y<sub>5</sub> = f(0.801) = <span class="ms">\( f(a3) = \frac{1}{1 + e^{-0.801}}
                                \)</span> = 0.69

                        </li>
                        <li><strong>Error = y<sub>target</sub> - y<sub>5</sub> = -0.19</strong></li>
                    </ul>
                    <p>To get closure to the desired output we need to update the weight.</p>
                    <p><strong>Each Weight changed by:</strong></p>
                    <ul>
                        <li><span class="ms">&Delta;w<sub>ij</sub> = &eta;&delta;<sub>j</sub>O<sub>i</sub></span>
                            <ul>
                                <li>&delta;<sub>j</sub> = O<sub>j</sub>(1 - O<sub>j</sub>)(t<sub>j</sub> - O<sub>j</sub>) if <i>j</i> is an output unit</li>
                                <li>&delta;<sub>j</sub> = O<sub>j</sub>(1 - O<sub>j</sub>)\( \sum_{k}\)&delta;<sub>k</sub>w<sub>kj</sub> if <i>j</i> is a hidden unit</li>
                            </ul>
                        </li>
                        <li>where &eta; is a constant called the learning rate</li>
                        <li>t<sub>j</sub> is the correct output for unit j</li>
                        <li>&delta;<sub>j</sub> is the error measure for unit j</li>
                        <li>O<sub>i</sub> represents the output of the unit <i>i</i> in the previous layer. In the case of a hidden or output unit, it refers to the activation value of that unit.</li>
                    </ul>
                    
                    <p><strong>Backward Pass: Compute &delta;<sub>3</sub>, &delta;<sub>4</sub> and
                            &delta;<sub>5</sub></strong></p>
                    <img src="../../images/sc9.jpeg" alt="">
                    <ul>
                        <li>For output unit:
                            <br>&delta;<sub>5</sub> = y<sub>5</sub>(1-y<sub>5</sub>)(y<sub>target</sub> - y<sub>5</sub>)
                            <br> = 0.69*(1-0.69)*(05-0.69) = -0.0406
                        </li>
                        <li>For hidden unit:
                            <br>&delta;<sub>3</sub> = y<sub>3</sub>(1-y<sub>3</sub>)w35*&delta;<sub>5</sub>
                            <br>0.68*(1-0.68)*(0.3*(-0.0406)) = -0.00265
                        </li>
                        <li>For hidden unit:
                            <br>&delta;<sub>4</sub> = y<sub>4</sub>(1-y<sub>4</sub>)w45*&delta;<sub>5</sub>
                            <br>0.6637*(1-0.6637)*(0.9*(-0.0406)) = -0.0082
                        </li>
                    </ul>
                    <p><strong>Compute new weights</strong></p>
                    <p>&Delta;w<sub>ij</sub> = &eta;&delta;<sub>j</sub>O<sub>i</sub></p>
                    <ul>
                        <li>&Delta;w<sub>13</sub> = &eta;&Delta;<sub>3</sub>x<sub>1</sub> = 1 * (-0.00265) * 0.35 =
                            −0.0009275
                            <br>&Delta;w<sub>13</sub>(new) = &Delta;w<sub>13</sub> + w<sub>13</sub>(old) = −0.0009275 +
                            0.1 = 0.0991
                        </li>
                        <li>&Delta;w<sub>14</sub> = &eta;&Delta;<sub>4</sub>x<sub>1</sub> = 1 * (-0.0082) * 0.35 =
                            -0.00287
                            <br>&Delta;w<sub>14</sub>(new) = &Delta;w<sub>14</sub> + w<sub>14</sub>(old) = -0.00287 +
                            0.4 = 0.3971
                        </li>
                        <li>&Delta;w<sub>23</sub> = &eta;&Delta;<sub>3</sub>x<sub>2</sub> = 1 * (-0.00265) * 0.9 =
                            -0.002385
                            <br>&Delta;w<sub>23</sub>(new) = &Delta;w<sub>23</sub> + w<sub>23</sub>(old) = -0.002385 +
                            0.4 = 0.7976
                        </li>
                        <li>&Delta;w<sub>24</sub> = &eta;&Delta;<sub>4</sub>x<sub>2</sub> = 1 * (-0.0082) * 0.9 =
                            -0.00738
                            <br>&Delta;w<sub>24</sub>(new) = &Delta;w<sub>24</sub> + w<sub>24</sub>(old) = -0.00738 +
                            0.6 = 0.5926
                        </li>
                        <li>&Delta;w<sub>35</sub> = &eta;&Delta;<sub>5</sub>y<sub>3</sub> = 1 * (-0.0406) * 0.68 =
                            -0.0276
                            <br>&Delta;w<sub>35</sub>(new) = &Delta;w<sub>35</sub> + w<sub>35</sub>(old) = -0.0276 + 0.3
                            = 0.2724
                        </li>
                        <li>&Delta;w<sub>45</sub> = &eta;&Delta;<sub>5</sub>y<sub>4</sub> = 1 * (-0.0406) * 0.6637 =
                            -0.0269
                            <br>&Delta;w<sub>45</sub>(new) = &Delta;w<sub>45</sub> + w<sub>45</sub>(old) = -0.0269 + 0.9
                            = 0.8731
                        </li>
                    </ul>
                    <p><strong>Forward Pass: Compute output y<sub>3</sub>, y<sub>4</sub> and y<sub>5</sub>.</strong></p>
                    <img src="../../images/sc10.jpeg" alt="">
                    <ul>
                        <li>y<sub>3</sub> = f(a1) = <span class="ms">\( f(a1) = \frac{1}{1 + e^{-a_1}} \)</span>
                            <br>a1 = (w<sub>13</sub> * x<sub>1</sub> ) + (w<sub>23</sub> * x<sub>2</sub>) = 0.7525
                            <br>y<sub>3</sub> = f(0.7525) = <span class="ms">\( f(a1) = \frac{1}{1 + e^{-0.7525}}
                                \)</span> = 0.6797

                        </li>
                        <li>y<sub>4</sub> = f(a2) = <span class="ms">\( f(a2) = \frac{1}{1 + e^{-a_2}} \)</span>
                            <br>a2 = (w<sub>14</sub> * x<sub>1</sub> ) + (w<sub>24</sub> * x<sub>2</sub>) = 0.6797
                            <br>y<sub>4</sub> = f(0.6797) = <span class="ms">\( f(a1) = \frac{1}{1 + e^{-0.6797}}
                                \)</span>
                            = 0.6620

                        </li>
                        <li>y<sub>5</sub> = f(a3) = <span class="ms">\( f(a3) = \frac{1}{1 + e^{-a_1}} \)</span>
                            <br>a3 = (w<sub>35</sub> * y<sub>3</sub> ) + (w<sub>45</sub> * y<sub>4</sub>) = 0.7631
                            <br>y<sub>5</sub> = f(0.7631) = <span class="ms">\( f(a3) = \frac{1}{1 + e^{-0.7631}}
                                \)</span> = 0.6820 (Network Output)

                        </li>
                        <li><strong>Error = y<sub>target</sub> - y<sub>5</sub> = -0.182</strong></li>
                    </ul>
                </div>
            </div>
            <div class="in">
                <h3>Radial Basis Function Network (RBFN)</h3>

<p><strong>Radial Basis Function Network (RBFN)</strong> is a type of artificial neural network that is widely used for classification, regression, and function approximation tasks. It works by using radial basis functions as activation functions and is particularly good at handling non-linear data.</p>

Key Concepts</strong></p>

<ul>
    <li>
        <strong>Radial Basis Function</strong>: 
        The core component of an RBFN is the <em>radial basis function</em>, which is used as the activation function. The most common radial basis function is the Gaussian function, which measures the distance between an input vector and a center point.
    </li>
    <li>
        <strong>Three-Layer Structure</strong>: 
        An RBFN typically has three layers:
        <ul>
            <li><strong>Input Layer</strong>: Receives the input data.</li>
            <li><strong>Hidden Layer</strong>: Contains neurons that apply the radial basis function to the input data.</li>
            <li><strong>Output Layer</strong>: Produces the final output, such as a classification label or regression value.</li>
        </ul>
    </li>
    <li>
        <strong>Centers and Weights</strong>: 
        In RBFNs, each neuron in the hidden layer has a center point. The distance between the input and this center is calculated, and the radial basis function is applied to this distance. The output is then weighted and passed to the output layer.
    </li>
</ul>

<p><strong>How RBFN Works</strong></p>

<ul>
    <li>
        <strong>Training Process</strong>: 
        Training an RBFN involves two steps:
        <ul>
            <li><strong>Step 1: Find Centers</strong>: First, the center points of the radial basis functions are determined using methods like k-means clustering.</li>
            <li><strong>Step 2: Adjust Weights</strong>: Next, the weights between the hidden layer and output layer are learned through optimization techniques like least squares or gradient descent.</li>
        </ul>
    </li>
    <li>
        <strong>Non-linear Mapping</strong>:
        RBFNs are effective for non-linear problems because the radial basis functions can map input data into a higher-dimensional space, making it easier to separate complex patterns.
    </li>
</ul>

<p><strong>Why Use RBFN?</strong></p>

<ul>
    <li><strong>Handles Non-Linear Data</strong>: RBFNs are ideal for problems where the relationship between input and output is non-linear, such as complex classification or regression tasks.</li>
    <li><strong>Fast Training</strong>: Compared to other types of neural networks, RBFNs can often be trained more quickly because only the weights between the hidden and output layers need to be optimized.</li>
    <li><strong>Good for Function Approximation</strong>: RBFNs excel in approximating unknown functions, making them useful for tasks like time series prediction and control systems.</li>
</ul>

<p><strong>Real-World Example</strong></p>

<p>Suppose you want to predict house prices based on features like location, size, and number of bedrooms. An RBFN can model the relationship between these features and house prices, even if the relationship is non-linear. After training, it can predict the price of a new house by applying radial basis functions to the input features and calculating the output based on learned weights.</p>

            </div>
        </div>
        <div class="wh">
            <h2>Feedback Neural Networks (Recurrent Neural Networks)</h2>
            <p>Feedback neural networks, also known as recurrent neural networks (RNNs), are a class of artificial
                neural networks where connections between the neurons form directed cycles, allowing information to be
                fed back into the network. Unlike feedforward networks where the information moves strictly in one
                direction, feedback networks allow for loops, meaning the network can retain information about previous
                inputs. This makes them suitable for tasks where the current output depends not only on the current
                input but also on past inputs, like sequence prediction, time-series forecasting, and language modeling.
            </p>
            <p><strong>Key Components:</strong></p>
            <ol>
                <li>Input Layer: The layer where the input data is received, similar to feedforward networks.</li>
                <li>Hidden Layers: These layers, like in feedforward networks, perform computations based on the input
                    data. However, in feedback networks, hidden layers often retain information about previous inputs,
                    enabling the network to learn from sequential patterns.</li>
                <li>Output Layer: This layer produces the final prediction or classification result. The number of
                    neurons depends on the task.</li>
                <li>Recurrent Connections: The hallmark of feedback networks is their recurrent connections, where
                    outputs of neurons can be fed back into themselves or previous layers. This feedback loop enables
                    the network to retain memory over time, a feature that's crucial for tasks like sequential data
                    processing.</li>
                <li>Weights and Biases: Similar to feedforward networks, feedback networks have weights and biases that
                    are adjusted during training to minimize the error between predicted and actual outputs.</li>
                <li>Activation Functions: These are used to introduce non-linearity into the network, which helps in
                    learning complex patterns.</li>
            </ol>
            <p><strong>Learning Process:</strong></p>
            <p>The training of feedback neural networks involves propagating the error back through time, which is done
                using algorithms such as Backpropagation Through Time (BPTT). Since the network has a memory of previous
                inputs, learning becomes more complex compared to feedforward networks. Feedback networks are capable of
                handling time-dependent data because they can learn from the temporal dependencies present in the input
                sequences.</p>
            <p><strong>Varianst of Feedback Networks</strong></p>
            <p>There are several important types of feedback networks that specialize in different tasks.
                <br>Two notable examples are:
            <ol>
                <li><strong>Hopfield Network</strong>: The Hopfield network is a type of recurrent neural network that
                    serves as a content-addressable memory system. It's designed for associative memory and pattern
                    recognition tasks. Each neuron in a Hopfield network is connected to every other neuron, forming a
                    fully connected network. Once trained, the network can retrieve a stored pattern even from partial
                    or noisy inputs.</li>
                <li><strong>Bidirectional Associative Memory (BAM)</strong>: BAM is another type of recurrent neural
                    network that is used for pattern recognition and associative memory. It can store pairs of patterns
                    (input-output pairs), and given one part of the pair, it can retrieve the other. Unlike the Hopfield
                    network, BAM works bidirectionally, meaning it can retrieve an output from a given input and vice
                    versa. It's often used for applications requiring associative recall.</li>
            </ol>
            </p>
            <div class="in">
                <h3>Hopfield Network</h3>

                <p>The <strong>Hopfield Network</strong> is a type of neural network used for remembering patterns and
                    retrieving them when given incomplete or noisy information. Think of it like your brain recognizing
                    a friend’s face even if they’re wearing sunglasses or a hat.</p>

                    <p><strong>Key Concepts:</strong></p>

                <ul>
                    <li>
                        <strong>Neurons and States</strong>:
                        The Hopfield network is made up of simple units called <em>neurons</em>. Each neuron can have
                        only two states: <strong>on</strong> or <strong>off</strong> (typically represented as
                        <code>+1</code> and <code>-1</code>).
                    </li>
                    <li>
                        <strong>Connections Between Neurons</strong>:
                        Every neuron is connected to every other neuron, but <em>not to itself</em>. These connections
                        have <em>weights</em>, which decide how strongly one neuron influences another.
                    </li>
                    <li>
                        <strong>Pattern Storage</strong>:
                        The Hopfield network can store patterns (like pictures, sounds, or any data). Once it learns a
                        pattern, it can recall it from partial or distorted input. For example, if the network is
                        trained to remember a face, it can still recognize it even if the face is blurry.
                    </li>
                    <li>
                        <strong>How the Network Works</strong>:
                        <ul>
                            <li>
                                <strong>Learning</strong>: The Hopfield network learns by adjusting the weights between
                                neurons based on the patterns you give it. This process ensures that the network can
                                later recall these patterns.
                            </li>
                            <li>
                                <strong>Recall</strong>: When you give the network a part of a pattern (like a blurry
                                version of a face), it updates the neuron states until it matches the closest pattern it
                                remembers. This process happens in small steps, one neuron at a time.
                            </li>
                        </ul>
                    </li>
                    <li>
                        <strong>Stable States</strong>:
                        A Hopfield network has special stable states, called <em>attractors</em>. Once the network
                        reaches a stable state, it stops changing. These stable states correspond to the patterns it has
                        learned.
                    </li>
                    <li>
                        <strong>Energy Minimization</strong>:
                        Hopfield networks work by trying to minimize an "energy" function. This means the network always
                        moves towards a more stable pattern, just like a ball rolling downhill until it reaches the
                        bottom.
                    </li>
                </ul>

                <p><strong>Why Use Hopfield Networks?</strong></p>

                <ul>
                    <li>They are great for <strong>associative memory</strong>, where you want to remember something
                        based on partial input.</li>
                    <li>They’re used in <strong>pattern recognition</strong>, such as recognizing handwriting, faces, or
                        other types of data.</li>
                </ul>

                <p><strong>Real-World Example</strong></p>

                <p>Imagine you give a Hopfield network a picture of a cat to remember. Later, you give it a blurry or
                    incomplete version of the cat, and the network will fill in the missing details to recall the full
                    image.</p>

            </div>
            <div class="in">
                <h3>Bidirectional Associative Memory (BAM)</h3>

                <p>The <strong>Bidirectional Associative Memory (BAM)</strong> is a type of recurrent neural network
                    that can recall patterns in both directions. It was introduced by Bart Kosko in 1988 and is useful
                    for associating pairs of patterns, where recalling one pattern can help retrieve its pair.</p>

                    <p><strong>Key Concepts</strong></p>

                <ul>
                    <li>
                        <strong>Bipolar Neurons</strong>:
                        BAM uses <em>bipolar neurons</em>, meaning each neuron can have values of <code>+1</code> or
                        <code>-1</code>. This is similar to Hopfield networks.
                    </li>
                    <li>
                        <strong>Two-Layer Network</strong>:
                        BAM consists of two layers of neurons, called the <em>X layer</em> and the <em>Y layer</em>.
                        These two layers are connected, allowing the network to associate a pattern in the X layer with
                        a pattern in the Y layer.
                    </li>
                    <li>
                        <strong>Bidirectional Recall</strong>:
                        The network can retrieve a pattern from one layer based on the input from the other layer. For
                        example, if you input a pattern in the X layer, it can recall the corresponding pattern in the Y
                        layer, and vice versa.
                    </li>
                </ul>

                <p><strong>How BAM Works</strong></p>

                <ul>
                    <li>
                        <strong>Learning Process</strong>:
                        BAM learns by adjusting the weights between the neurons in the X and Y layers. When given a pair
                        of patterns (one in each layer), it strengthens the connections between the neurons that are
                        active in both patterns.
                    </li>
                    <li>
                        <strong>Recall Process</strong>:
                        During recall, if you give the network part of a pattern in the X layer, it will compute the
                        corresponding pattern in the Y layer by using the learned weights, and vice versa. This happens
                        in both directions, hence the term "bidirectional."
                    </li>
                </ul>

                <p><strong>Associative Memory in BAM</strong></p>

                <ul>
                    <li>
                        BAM is an <strong>associative memory</strong> network, meaning it stores patterns in pairs. It
                        learns associations between two sets of patterns, so it can retrieve one based on the other.
                    </li>
                    <li>
                        It is different from Hopfield networks because BAM can associate two completely different
                        patterns, one in each layer. Hopfield networks only recall variations of the same pattern.
                    </li>
                </ul>

                <p><strong>Why Use BAM?</strong></p>

                <ul>
                    <li>BAM is useful for <strong>pattern association</strong>, where two different sets of patterns
                        need to be associated with each other.</li>
                    <li>It can be applied in <strong>image recognition</strong>, <strong>language translation</strong>,
                        and other tasks where pairs of related data need to be recalled together.</li>
                </ul>

                <h3>Real-World Example</h3>

                <p>Imagine you train a BAM network to associate words in English with their French translations. When
                    you input the English word "cat" into the X layer, the network will recall its French translation
                    "chat" in the Y layer. You can also input "chat" into the Y layer, and the network will recall "cat"
                    in the X layer.</p>

            </div>
        </div>
        <div class="wh">
            <h2>Self-Organizing Feature Maps (SOFM)</h2>
            <p>Self-Organizing Feature Maps (SOFMs), also known as Kohonen networks, are a type of artificial neural
                network that use unsupervised learning to produce a low-dimensional representation (typically 2D) of
                input data. Unlike supervised learning models, SOFMs learn from the structure of the data without
                requiring labeled outputs. These networks are particularly useful for tasks like clustering, data
                visualization, and dimensionality reduction. SOFMs are known for preserving the topological structure of
                the input space, meaning similar inputs are mapped to nearby locations on the output map.</p>
            <p><strong>Learning Process:</strong></p>
            <p>SOFM training starts with random initialization of the weights. As each input is processed, the BMU is
                found, and its weights, along with those of its neighbors, are updated to move closer to the input
                vector. The learning rate and neighborhood size typically decrease over time, allowing the network to
                fine-tune its mapping.
                <br>SOFMs are used in a variety of applications, including pattern recognition, data clustering, and
                feature extraction, due to their ability to group similar data points together and maintain topological
                relationships.
            </p>
            <p><strong>Variants of Self-Organizing Feature Maps</strong></p>
            <p>Several extensions and related models to SOFM have been developed, each with specific features for
                different applications. Two notable variants are:</p>
            <ol>
                <li><strong>Self-Organizing Maps (SOM)</strong>: SOMs are the most well-known type of self-organizing
                    feature maps, introduced by Teuvo Kohonen. They are widely used for tasks such as data clustering,
                    pattern recognition, and visualization of high-dimensional data. The SOM algorithm reduces the
                    dimensions of data by mapping input vectors into a two-dimensional grid while preserving their
                    topological structure.</li>
                <li><strong>Learning Vector Quantization (LVQ)</strong>: LVQ is a type of supervised learning algorithm
                    based on the principles of self-organizing maps. It combines the clustering capability of SOMs with
                    the ability to classify data. LVQ networks are trained using labeled data, and the weight vectors
                    are adjusted to improve classification accuracy. LVQ is commonly used in classification problems
                    where the goal is to assign inputs to predefined classes.</li>
            </ol>
            <div class="in">
                <h3>Self-Organizing Maps (SOM)</h3>

                <p><strong>Self-Organizing Maps (SOM)</strong>, also known as Kohonen maps (named after their inventor
                    Teuvo Kohonen), are a type of unsupervised learning neural network. They are used for clustering and
                    visualizing high-dimensional data by organizing similar data points together in a two-dimensional
                    grid.</p>

                    <p><strong>Key Concepts</strong></p>

                <ul>
                    <li>
                        <strong>Unsupervised Learning</strong>:
                        SOM uses <em>unsupervised learning</em>, meaning it does not require labeled data. Instead, it
                        finds patterns and structures in the input data on its own, grouping similar inputs together.
                    </li>
                    <li>
                        <strong>Topological Map</strong>:
                        SOM creates a <em>topological map</em>, where similar input patterns are mapped close to each
                        other on a two-dimensional grid, helping in visualizing high-dimensional data.
                    </li>
                    <li>
                        <strong>Neurons and Grid</strong>:
                        The network consists of a grid of neurons, where each neuron represents a specific group or
                        cluster of input data. Each neuron has a weight vector, which adjusts to match the input data
                        during training.
                    </li>
                </ul>

                <p><strong>How SOM Works</strong></p>

                <ul>
                    <li>
                        <strong>Training</strong>:
                        SOM training involves presenting input data to the network and adjusting the weights of the
                        neurons to better match the input. The process is iterative, and with each step, the neurons
                        that are closest to the input adjust their weights more significantly.
                    </li>
                    <li>
                        <strong>Best Matching Unit (BMU)</strong>:
                        For each input, the neuron whose weight vector is closest to the input data (called the <em>Best
                            Matching Unit</em>, or BMU) is identified. This BMU and its neighboring neurons update their
                        weights to move closer to the input vector.
                    </li>
                    <li>
                        <strong>Neighborhood Function</strong>:
                        The adjustment of weights not only affects the BMU but also its neighbors. Neurons that are
                        closer to the BMU adjust more than those further away. This creates a smooth transition on the
                        map, grouping similar data points together.
                    </li>
                </ul>

                <p><strong>Why Use SOM?</strong></p>

                <ul>
                    <li><strong>Data Visualization</strong>: SOM is commonly used for visualizing complex and
                        high-dimensional data in a simple 2D format, making it easier to understand patterns and
                        clusters.</li>
                    <li><strong>Clustering</strong>: It is excellent for clustering similar data points together without
                        any prior knowledge of the categories.</li>
                    <li><strong>Dimensionality Reduction</strong>: SOM helps reduce the dimensions of data, while still
                        preserving its structure, so you can analyze it more easily.</li>
                </ul>

                <p><strong>Real-World Example</strong></p>

                <p>Suppose you have a dataset of customers’ shopping habits, including hundreds of variables like age,
                    income, and products purchased. A SOM can help you organize these customers into groups based on
                    similar shopping behaviors. Once trained, you can visualize these groups on a 2D map, where
                    customers with similar habits are located near each other on the grid.</p>

            </div>
            <div class="in">
                <h3>Learning Vector Quantization (LVQ)</h3>

                <p><strong>Learning Vector Quantization (LVQ)</strong> is a supervised learning algorithm used for
                    classification tasks. It is based on the competitive learning principle and works by finding
                    prototypes that represent different classes in the data. LVQ is commonly used for pattern
                    recognition, where each prototype acts as a representative of a specific class.</p>

                    <p><strong>Key Concepts</strong></p>

                <ul>
                    <li>
                        <strong>Supervised Learning</strong>:
                        LVQ is a <em>supervised learning</em> algorithm, which means it requires labeled training data
                        to learn how to classify inputs. The goal is to assign input data to predefined categories.
                    </li>
                    <li>
                        <strong>Prototypes</strong>:
                        LVQ uses <em>prototypes</em>, which are reference points that represent different classes in the
                        data. These prototypes are adjusted during training to better match the input data and improve
                        classification accuracy.
                    </li>
                    <li>
                        <strong>Winner-Takes-All Rule</strong>:
                        When an input vector is presented to the network, the prototype that is closest to the input is
                        selected as the "winner." This winner prototype is updated to better match the input,
                        reinforcing its representation of that class.
                    </li>
                </ul>

                <p><strong>How LVQ Works</strong></p>

                <ul>
                    <li>
                        <strong>Initialization</strong>:
                        At the beginning, a set of prototypes is initialized. These prototypes represent the different
                        classes in the training data, and their positions will be adjusted throughout the training
                        process.
                    </li>
                    <li>
                        <strong>Training Process</strong>:
                        During training, input vectors are presented to the network, and the closest prototype (based on
                        distance) is identified. If the prototype correctly represents the input class, it is moved
                        closer to the input. If it belongs to a different class, it is moved further away.
                    </li>
                    <li>
                        <strong>Adjustment of Prototypes</strong>:
                        The movement of prototypes is done to reduce classification errors. Prototypes for the correct
                        class are adjusted towards the input, while those for incorrect classes are adjusted away,
                        helping the network to better classify new data.
                    </li>
                </ul>

                <p><strong>Why Use LVQ?</strong></p>

                <ul>
                    <li><strong>Simple and Interpretable</strong>: LVQ provides a simple and interpretable way to
                        classify data based on prototypes. The decision boundaries created are easy to visualize and
                        understand.</li>
                    <li><strong>Effective for Classification</strong>: LVQ is highly effective for classification
                        problems, especially when there are clear clusters in the data that can be represented by
                        prototypes.</li>
                    <li><strong>Adaptable to Different Problems</strong>: LVQ can be applied to a wide variety of
                        classification problems, from image recognition to medical diagnosis, making it versatile.</li>
                </ul>

                <p><strong>Real-World Example</strong></p>

                <p>Imagine you are classifying different types of flowers based on features like petal length and width.
                    Using LVQ, you can define prototypes for each flower type (such as roses, lilies, and tulips). As
                    the network learns, these prototypes will adjust to represent each flower category more accurately,
                    allowing the model to classify new flowers correctly.</p>

            </div>
        </div>
    </div>
    <script src="../../../../public/main.js"></script>
</body>

</html>