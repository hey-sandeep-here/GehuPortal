<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Introduction to Soft Computing</title>
    <link rel="stylesheet" href="../../../../public/style.css">
    <link rel="icon" href="../../../../public/logo/favicon_io/favicon.ico">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body class="bg-c">
    <div id="mySidepanel" class="sidepanel">
        <a href="javascript:void(0)" class="closebtn" onclick="closeNav()">×</a>
        <a href="../index.html" class="home">back</a>
        <div class="fix-column-links">
            <a href="#" class="link"></a>
            <div class="botbut">
                <a href="../unit2/index.html" class="link">Next Topic &rarr;</a>
            </div>
        </div>
    </div>
    <div id="navbar" class="grad">
        <div>
            <div class="openbtn" onclick="openNav()">
                <div id="nav-icon1" for="nav-menu1">
                    <span></span>
                    <span></span>
                    <span></span>
                </div>
            </div>
        </div>
        <div>
            <h2>Introduction to Soft Computing</h2>
        </div>
    </div>
    <div class="content-box">
        <div class="wh">
            <h2>Computing</h2>
            <p>Before diving into soft computing, it's essential to first understand what computing is and familiarize
                ourselves with the core terminologies related to computing.</p>
            <ul>
                <li>The following diagram represents the basic process that occurs in computing:</li>
            </ul>
            <img src="../../images/sc2.jpeg" alt="">
            <ul>
                <li>In this diagram, we observe that there is a function, <strong>f</strong>, which takes some input,
                    <strong>x</strong>, and produces an output, <strong>y</strong>.
                    The input is referred to as the <strong>Antecedent</strong>, while the output is called the
                    <strong>Consequent</strong>.
                </li>
                <li>The function <strong>f</strong> can also be called a <strong>formal method</strong>,
                    <strong>algorithm</strong>, or a <strong>mapping function</strong>. It represents the logic or steps
                    used to process the input and generate the output.
                </li>
                <li>The middle part of this diagram is known as the <strong>computing unit</strong>, where the function
                    resides. This is where we feed the input, and a process occurs to convert that input into the
                    desired output <strong>y</strong>.</li>
                <li>In the computing process, the steps that guide how the input is manipulated are called
                    <strong>control actions</strong>. These control actions ensure that the input gradually approaches
                    the desired output. The moment the process completes, we obtain the final result, known as the
                    <strong>Consequent</strong>.
                </li>
                <li><strong>Basic Characteristics Related to Computing:</strong>
                    <ol>
                        <li><strong>Precise Solution:</strong> Computing is used to produce a solution that is exact and
                            definitive.</li>
                        <li><strong>Unambiguous & Accurate:</strong> The control actions within the computing unit must
                            be unambiguous, meaning they must have only one interpretation. Each control action should
                            also be accurate to ensure that the process is valid and reliable.</li>
                        <li><strong>Mathematical Model:</strong> A well-defined algorithm is a requirement for solving
                            any problem through computing. This algorithm is essentially a mathematical model that
                            represents the problem and its solution process.</li>
                    </ol>
                </li>
                <li><strong>In computing, there are two main types</strong>:
                    <ol>
                        <li>Hard Computing</li>
                        <li>Soft Computing</li>
                    </ol>
                </li>
            </ul>
        </div>
        <div class="wh">
            <h3>Hard Computing</h3>
            <ul>
                <li><strong>Definition of Hard Computing:</strong>
                    Hard computing refers to a traditional computing approach where the results are always precise and
                    exact. This is because hard computing relies on well-defined mathematical models and algorithms to
                    solve problems. There is no room for approximation, as every calculation or action leads to a
                    deterministic output.
                </li>
                <li><strong>Main Features of Hard Computing:</strong>
                    <ul>
                        <li><strong>Exact Results:</strong> The results in hard computing are always exact. This means,
                            whenever we solve a problem using hard computing methods, the answer will always be the same
                            and correct. There is no room for uncertainty or approximation.</li>
                        <li><strong>Clear Control Actions:</strong>
                            In hard computing, the steps or actions we take to solve a problem are clear and have only
                            one meaning. For example, when following an algorithm, each step must be clearly understood
                            and should only have one possible result. There should be no confusion or multiple meanings
                            for a single step. This is called being "unambiguous."
                        </li>
                        <li><strong>Based on Mathematical Models:</strong>
                            All the actions in hard computing are based on well-defined mathematical rules or formulas.
                            This means that each step we take while solving a problem has a proper mathematical
                            explanation behind it. These steps follow a fixed pattern or method, which helps in solving
                            the problem in a precise way.
                        </li>
                    </ul>
                </li>
                <li><strong>Examples of Hard Computing:</strong>
                    <ol>
                        <li><strong>Numerical Problems:</strong> Problems that require accurate mathematical
                            calculations, like solving equations or doing arithmetic, are examples of hard computing.
                        </li>
                        <li><strong>Searching and Sorting Algorithms:</strong> In computer science, methods like
                            searching for an item in a list or sorting a list in a particular order are solved using
                            hard computing techniques because they always give an exact answer.</li>
                        <li><strong>Computational Geometry Problems:</strong> These are problems related to shapes,
                            distances, and areas in geometry. For example, calculating the shortest distance between two
                            points or finding the area of a triangle requires exact methods, which is where hard
                            computing comes in.
                        </li>
                    </ol>
                </li>
            </ul>

        </div>
        <div class="wh">
            <h2>Soft Computing</h2>
            <ul>
                <li>Soft Computing is an approach to computing that models the human mind’s ability to make decisions in
                    an uncertain, imprecise, or complex environment. Unlike traditional, or "hard," computing, which
                    relies on exact, binary logic (0s and 1s), soft computing deals with approximation, flexibility, and
                    learning from experience to solve complex real-world problems.</li>
                <li>Soft computing techniques focus on developing systems that can handle ambiguity, uncertainty, and
                    approximation, making them well-suited for fields like artificial intelligence (AI), pattern
                    recognition, and robotics.</li>
            </ul>
            <div class="in">
                <h3>Difference between Hard and Soft Computing</h3>
                <img src="../../images/sc1.png" alt="">
            </div>
            <div class="in">
                <h3>Requirement of Soft Computing</h3>
                <p>Soft computing is essential because many real-world problems are too complex for traditional
                    computing methods. Systems must handle:</p>
                <ul>
                    <li><strong>Uncertainty</strong>: Data may not always be precise, requiring flexible models.</li>
                    <li><strong>Partial truths</strong>: Situations where a simple binary "true/false" answer isn’t
                        sufficient.</li>
                    <li><strong>Imprecision</strong>: Many problems, such as human language processing, involve vague or
                        imprecise inputs.</li>
                    <li><strong>Complex systems</strong>: Soft computing helps in dealing with complex, non-linear
                        systems, like weather prediction or stock market analysis.</li>
                </ul>
            </div>
            <div class="in">
                <h3>Major Areas of Soft Computing</h3>
                <ol>
                    <li><strong>Fuzzy Logic</strong>: Mimics human reasoning, allowing for more than just "true" or
                        "false" outcomes. It’s widely used in control systems, such as thermostats or automated vehicle
                        systems.</li>
                    <li><strong>Neural Networks</strong>: Modeled after the human brain, these networks learn from data
                        and improve over time. They are used in areas like image recognition, speech processing, and
                        autonomous systems.</li>
                    <li><strong>Genetic Algorithms</strong>: Inspired by natural selection, these algorithms "evolve"
                        solutions over generations. They are useful for optimization problems, such as route planning or
                        complex decision-making.</li>
                    <li><strong>Probabilistic Reasoning</strong>: Deals with uncertainty using probabilities. It is
                        useful in situations where outcomes are not deterministic, like predicting stock market trends
                        or diagnosing diseases.</li>
                </ol>
            </div>
            <div class="in">
                <h3>Applications of Soft Computing</h3>
                <p>Soft computing techniques are applied in a variety of fields, including:</p>
                <ul>
                    <li><strong>Artificial Intelligence (AI)</strong>: Many AI systems rely on neural networks and fuzzy
                        logic to emulate human decision-making.</li>
                    <li><strong>Pattern Recognition</strong>: Soft computing helps identify patterns in complex data,
                        such as handwriting recognition or facial recognition.</li>
                    <li><strong>Robotics</strong>: Soft computing enables robots to navigate environments with uncertain
                        data, making them more adaptable.</li>
                    <li><strong>Data Mining</strong>: Soft computing techniques are used to discover patterns and
                        relationships in large datasets.</li>
                    <li><strong>Control Systems</strong>: Fuzzy logic controllers are used in industrial systems, like
                        temperature control in manufacturing plants.</li>
                    <li><strong>Medicine</strong>: Soft computing helps in diagnosing diseases, predicting patient
                        outcomes, and optimizing treatment plans.</li>
                    <li><strong>Economics and Finance</strong>: Used in predicting market trends, risk analysis, and
                        portfolio optimization.</li>
                </ul>
            </div>
        </div>
        <div class="wh">
            <h2>Fundamentals of ANN</h2>
            <p>Artificial Neural Networks (ANNs) are a key component of modern artificial intelligence, inspired by the
                way biological neural networks in the human brain function. ANNs are designed to mimic the brain's
                ability to process information, learn from data, and make decisions. This section explores the
                fundamentals of ANNs, starting with an understanding of biological neural networks, which serve as the
                foundation for developing these sophisticated computational models. By examining how neurons interact in
                the human brain, we can better appreciate how artificial networks are structured and how they perform
                various tasks.</p>

            <div class="in">
                <h3>Biological Neural Network</h3>
                <ul>
                    <li>First, we should understand that a neural network is a massive collection of neurons that are
                        interconnected with one another.</li>
                    <li>The human brain contains billions of neurons, approximately 10<sup>13</sup>, and all these
                        neurons are interconnected to form a complex network.</li>
                    <li>The following is a diagram of a single biological neuron:</li>
                </ul>
                <img src="../../images/sc3.jpeg" alt="Diagram of Biological Neuron">
                <ul>
                    <li>A biological neuron consists of dendrites, which are responsible for collecting inputs. Inside
                        the neuron, there is a cell body (also known as the soma), and within the cell body, we find the
                        nucleus. The dendrites collect the input signals, and the cell body processes that input. Once
                        processed, the output is transferred via the axon. The axon is the part of the neuron that
                        carries the output signals to other neurons.
                    </li>
                    <li>In the human brain, we have billions of neurons, and the dendrites of one neuron connect with
                        the axons of other neurons. The point where two neurons connect is called a synapse. Information
                        is stored and transferred across these synapses. As we store more information in our brains, the
                        synapses strengthen, allowing us to retain that information. With billions of neurons, we also
                        have billions of synapses, which play a key role in memory and learning.</li>
                    <li>For example, when we read a question in an exam, the information is sent to our brain through
                        neurons. Another example is when a mosquito bites us; the signal of pain is sent to our brain,
                        and we respond to it through neural signals.</li>
                    <li><strong>Definition of Biological Neural Network:</strong>
                        A biological neural network is a network of neurons that processes and transmits information in
                        the brain. It is the basis of how humans think, learn, and make decisions. The neurons
                        communicate with each other through synapses, which strengthen as we store more information,
                        allowing us to retain and recall data.
                    </li>
                    <li>The development of Artificial Neural Networks (ANNs) was inspired by biological neural networks
                        (BNNs). Researchers, observing how the human brain is capable of understanding questions,
                        thinking, and making decisions without any external control, started studying BNNs closely. They
                        wanted to replicate this ability in machines.
                    </li>
                    <li>This is how the concept of artificial neural networks (ANNs) was born. Researchers aimed to
                        build machines that could think and act like humans, think rationally, and perform tasks without
                        human intervention. The structure and function of ANNs are modeled on biological neural
                        networks, which is why BNNs played a significant role in the development of ANNs.</li>
                </ul>
            </div>
            <div class="in">
                <h3>Artificial Neural Network</h3>
                <ul>
                    <li>An Artificial Neural Network (ANN) is designed to develop a computational system that models the
                        human brain. This model allows ANNs to perform a variety of tasks more efficiently than
                        traditional computer systems. For example, while traditional computers might take a long time to
                        perform a task, an ANN can complete the same task in a much shorter period. ANNs are used for
                        various applications such as classification, pattern recognition, and optimization. Essentially,
                        ANNs are developed to mimic the functionality of the human brain and perform tasks faster and
                        more efficiently than conventional systems.</li>
                    <li>The main objective of an ANN is to process and analyze data in a manner similar to how the human
                        brain does, allowing it to make decisions, recognize patterns, and solve complex problems with
                        speed and accuracy.</li>
                    <li>We can also describe an ANN as an efficient information processing system that resembles the
                        characteristics of a biological neural network. ANNs are designed to process information in a
                        way that is similar to how the brain processes information.</li>
                    <li>An ANN consists of highly interconnected processing elements known as nodes. In the human brain,
                        these processing elements are neurons. Similarly, in ANNs, nodes act like neurons and are
                        interconnected with each other through links. Each node receives inputs, processes them, and
                        sends outputs to other nodes. This network of nodes and connections allows ANNs to perform
                        complex tasks by processing information in a distributed manner.</li>
                    <li>For example, consider an ANN with two input nodes (A and B) connected to one output node (C).
                        Node A is connected to node C, and node B is also connected to node C. Suppose node A receives
                        an input signal called x1 and node B receives an input signal called x2. The output node C will
                        receive a combined signal y. We assign weights to the connections between the nodes: w1 for the
                        connection between A and C, and w2 for the connection between B and C. <br>
                        <img src="../../images/sc4.jpeg" alt=""><br>
                        The weights are crucial because they determine the strength and importance of each input signal.
                        By adjusting the weights, the ANN can learn which inputs are more significant for making
                        accurate predictions or decisions. The net input to node C is calculated as follows:
                        <br>
                        Net Input = x1 * w1 + x2 * w2
                        <br>
                        This calculation provides the net input to node C, but to determine the actual output, we need
                        to apply an activation function to the net input. The activation function helps to decide
                        whether the neuron should be activated or not. After applying the activation function, we get
                        the final output for node C.

                        <br>
                        This example illustrates a simple ANN structure. In more complex ANNs, there can be multiple
                        input nodes (A, B, C, D, E, F), each with its own input signals (x1, x2, x3, x4, x5, etc.) and
                        weights (w1, w2, etc.). The net input to the output node is calculated similarly, but with many
                        more inputs and weights. The final output is determined after applying the activation function
                        to the net input.
                    </li>
                </ul>
            </div>
            <div class="in">
                <h3>Difference between ANN and BNN</h3>
                <p>
                <p>Artificial Neural Networks (ANNs) and Biological Neural Networks (BNNs) are both networks of neurons,
                    but they function differently. While BNNs exist naturally in the human brain, ANNs are man-made
                    systems created to mimic the brain's functioning. In this section, we’ll explore the key differences
                    between these two types of neural networks.</p>
                </p>
                <img src="../../images/sc5.png" alt="">
            </div>
        </div>
        <div class="wh">
            <h2>Building Blocks of Artificial Neural Networks (ANN)</h2>
            <p>To understand Artificial Neural Networks (ANN), we must first examine its foundational components. Just
                like any structure, a neural network is built upon certain key elements that define how it processes
                information, learns from data, and makes predictions.</p>
            <div class="in">
                <h3>1: Architecture of ANN</h3>
                <p>Architecture refers to the layout or structure of an ANN. It is how the neurons (units) are organized
                    in layers and how these layers are connected to each other.</p>
                <ul>
                    <li>Layers: An ANN typically consists of three types of layers:
                        <ul>
                            <li>Input Layer: Receives the raw data (like images, numbers, etc.) and passes it on to the
                                next layer.</li>
                            <li>Hidden Layer(s): These layers process the input and extract patterns. The number of
                                hidden layers and neurons in each layer can vary.</li>
                            <li>Output Layer: Provides the final result (e.g., a classification label or prediction).
                            </li>
                        </ul>
                    </li>
                </ul>
                <pre>
                    <code>
Input Layer       Hidden Layer       Output Layer
  (3 nodes)         (4 nodes)           (2 nodes)
    o                  o                    o
    | \              / | \                / |
    |  \            /  |  \              /  |
    o---o----------o---o---o------------o   o
    |  / \        / \  |  / \          /    |
    | /   \      /   \ | /   \        /     |
    o      \    /     o       \      /      o
            \  /               \    /
             o------------------o--o
The Input Layer has 3 nodes representing features (inputs).
The Hidden Layer has 4 nodes where computations happen.
The Output Layer has 2 nodes representing the final outputs or predictions.
                    </code>
                </pre>
                <p>The architecture of a neural network defines how data flows through the network, from input to
                    output, and how decisions are made at each step.</p>
                <ul>
                    <li>Connection with Weights: The architecture alone does not make the network functional. The magic
                        happens when we assign weights to the connections between neurons. These weights determine the
                        strength and impact of each connection on the final output.</li>
                </ul>
            </div>
            <div class="in">
                <h3>2: Setting of Weights</h3>
                <p>Weights are numerical values that control how much influence one neuron has over another. Every
                    connection between neurons has a weight associated with it, and these weights are learned during the
                    training process.</p>
                <ul>
                    <li>Initial Weights: At the start, weights are usually assigned randomly. These weights are adjusted
                        as the network learns from the data.</li>
                    <li>Role of Weights: The higher the weight between two neurons, the stronger the connection, meaning
                        the output from one neuron has a greater influence on the next neuron’s decision.</li>
                    <li>Learning: During training, the network adjusts the weights to minimize errors in its
                        predictions. This process is called training the network, and it’s essential for the network’s
                        ability to learn from data.</li>
                </ul>
                <p>Connection with Activation Functions: Once the weights determine how much influence one neuron’s
                    output has, we need a mechanism to decide whether this output should be passed forward or
                    "activated." That’s where activation functions come in.</p>
            </div>
            <div class="in">
                <h3>3: Activation Functions</h3>
                <p>An activation function is a mathematical function that determines whether a neuron should be
                    activated (fired) based on the weighted sum of its inputs. It introduces non-linearity to the
                    network, allowing it to solve complex problems.</p>
                <ul>
                    <li>Importance of activation function: let us assume a person is performing some task. To make the
                        task more efficient and to obtain correct results, some force or motivation may be given. This
                        force or motivation helps in achieving the correct results. In a similar way, the activation
                        function is applied over the net input of the network to calculate the output of an ANN so that
                        we get a better output or result.</li>
                </ul>
                <p>Now we will discuss each of the activation functions one by one:</p>

                <p><strong>1: Identity Function</strong></p>
                <ul>
                    <li>Also known as the linear function because the output is identical to the input.</li>
                    <li>It can be defined as: <br>
                        <span class="ms">f(x) = x</span> for all x. <br>
                        Here, if the net input is x, then the output will also be x.
                    </li>
                    <li>The input layer often uses the identity activation function because no transformation is needed.
                    </li>
                </ul>

                <p><strong>2: Binary Step Function</strong></p>
                <ul>
                    <li>This function can be defined as:<br>
                        <span class="ms">\( f(x) = \begin{cases}
                            1 & \text{if } x \geq \theta \\
                            0 & \text{if } x < \theta \end{cases} \)</span><br>
                                where &theta; is the threshold value. If the net input (x) is greater than or equal to
                                this threshold value,
                                the output is 1, otherwise, it is 0.
                    </li>
                    <li>It is widely used in single-layer neural networks where the output needs to be binary (either 0
                        or 1).</li>
                </ul>

                <p><strong>3: Bipolar Step Function</strong></p>
                <ul>
                    <li>Similar to the binary step function, but it outputs either +1 or -1 instead of 1 or 0.</li>
                    <li>It can be defined as:<br>
                        <span class="ms">\( f(x) = \begin{cases}
                            1 & \text{if } x \geq \theta \\
                            -1 & \text{if } x < \theta \end{cases} \)</span>
                    </li>
                    <li>Used when outputs are expected to be in the range of +1 and -1, often in single-layer networks.
                    </li>
                </ul>

                <p><strong>4: Sigmoidal Activation Functions</strong></p>
                <p>Sigmoidal functions introduce non-linearity to the network and are widely used in
                    backpropagation-based neural networks. There are two main types:</p>

                <p><strong>a) Binary Sigmoidal Function (Logistic Function)</strong></p>
                <ul>
                    <li>It can be defined as:<br>
                        <span class="ms">\( f(x) = \frac{1}{1 + e^{-\lambda x}} \)</span><br>
                        where λ (lambda) is the steepness parameter, and x is the net input.
                    </li>
                    <li>The output of the binary sigmoidal function is always between 0 and 1.</li>
                    <li>This function has a peculiar property: its derivative is:<br>
                        <span class="ms">\( f'(x) = \lambda f(x) (1 - f(x)) \)</span>
                    </li>
                </ul>

                <p><strong>b) Bipolar Sigmoidal Function</strong></p>
                <ul>
                    <li>It can be defined as:<br>
                        <span class="ms">\( f(x) = \frac{2}{1 + e^{-\lambda x}} - 1 \)</span><br>
                        where λ (lambda) is the steepness parameter, and x is the net input.
                    </li>
                    <li>The output of the bipolar sigmoidal function ranges from -1 to +1.</li>
                    <li>Its derivative is:<br>
                        <span class="ms">\( f'(x) = \frac{\lambda}{2} (1 + f(x)) (1 - f(x)) \)</span>
                    </li>
                </ul>

                <p><strong>5: Ramp Activation Function</strong></p>
                <ul>
                    <li>This function is a combination of step and linear functions.</li>
                    <li>It can be defined as:<br>
                        <span class="ms">\( f(x) = \begin{cases}
                            1 & \text{if } x > 1 \\
                            0 & \text{if } x < 0 \\ x & \text{if } 0 \leq x \leq 1 \end{cases} \)</span>
                    </li>
                    <li>It outputs 0 for inputs less than 0, increases linearly with inputs between 0 and 1, and outputs
                        1 for inputs greater than 1.</li>
                </ul>

                <p>Activation functions play a vital role in artificial neural networks by introducing non-linearity and
                    helping the network learn complex patterns.</p>


            </div>
            <div class="in">
                <h3>Sigmoid Activation Function Solved Example</h3>
                <img src="../../images/sc6.jpeg" alt="Neural Network Diagram">

                <p>In this case, we have a neural network with an input layer and an output layer. The input layer has
                    three neurons, and the output layer has one neuron. The inputs are \(0.8\), \(0.6\), and \(0.4\).
                    The bias weight is \(0.35\). The weights associated with the three neurons are \(0.1\), \(0.3\), and
                    \(-0.2\).</p>

                <p>There are two types of sigmoid functions:</p>
                <ul>
                    <li><strong>Binary Sigmoid Activation Function</strong>: The equation is
                        <span class="ms">\(y = F(y_n) = \frac{1}{1 + e^{-y_n}}\)</span>
                        where \(y_n\) is the net input to that particular neuron.
                    </li>

                    <li><strong>Bipolar Sigmoid Activation Function</strong>: The equation is
                        <span class="ms">\(y = F(y_n) = \frac{2}{1 + e^{-y_n}} - 1\)</span>
                        where again we need to know the net input \(y_n\).
                    </li>
                </ul>

                <p>To calculate the net input \(y_n\), we find the sum of the product of the inputs and weights. The
                    equation looks like this:</p>
                \(y_n = B + \sum_{i=1}^{n} (x_i \cdot w_i)\)
                <p>In this case, \(n\) is the number of input neurons, which is 3.</p>

                <p>Expanding the equation:</p>
                \(y_n = B + (x_1 \cdot w_1) + (x_2 \cdot w_2) + (x_3 \cdot w_3)\)

                <p>Substituting the values:</p>
                <ul>
                    <li>Bias (\(B\)) = \(0.35\)</li>
                    <li>\(x_1 = 0.8, \, w_1 = 0.1\)</li>
                    <li>\(x_2 = 0.6, \, w_2 = 0.3\)</li>
                    <li>\(x_3 = 0.4, \, w_3 = -0.2\)</li>
                </ul>

                <p>Now solving the equation:</p>
                \(y_n = 0.35 + (0.8 \cdot 0.1) + (0.6 \cdot 0.3) + (0.4 \cdot -0.2)\)
                <p>After calculation, we get \(y_n = 0.53\) as the net input to the neuron.</p>

                <p>Now we can use this net input to find the outputs:</p>
                <ul>
                    <li><strong>Binary Sigmoid Activation Function:</strong> Using the net input in the binary sigmoid
                        equation, we get:
                        <span class="ms">\( \text{output} = \frac{1}{1 + e^{-0.53}} \approx 0.628\)</span>
                    </li>

                    <li><strong>Bipolar Sigmoid Activation Function:</strong> Using the net input in the bipolar sigmoid
                        equation, we get:
                        <span class="ms">\( \text{output} = \frac{2}{1 + e^{-0.53}} - 1 \approx 0.257\)</span>
                    </li>
                </ul>
            </div>
        </div>
        <div class="wh">
            <h2>McCulloch-Pitts Neuron</h2>

            <p>The McCulloch-Pitts (MP) neuron, introduced in 1943 by Warren McCulloch and Walter Pitts, is one of the
                earliest models of artificial neural networks. This pioneering work laid the foundation for the field of
                neural computing and artificial intelligence. The MP neuron was designed to mimic the functioning of
                biological neurons in the human brain, aiming to represent logical operations in a simplified manner.
                Unlike more complex models, the MP neuron operates based on binary inputs and outputs, effectively
                simulating the way neurons fire in response to stimuli. As such, it serves as a fundamental building
                block in understanding neural networks and provides insights into how information processing occurs
                within more sophisticated models. This model is crucial for grasping essential concepts in neural
                networks, including activation functions, thresholds, and the basic principles of learning.</p>


            <h3>Architecture of McCulloch-Pitts Neuron</h3>
            <p>The architecture of the MP neuron consists of two layers:</p>
            <ul>
                <li><strong>Input Layer:</strong> Contains the input neurons.</li>
                <li><strong>Output Layer:</strong> Contains the output neuron.</li>
            </ul>
            <p>The input layer neurons are connected to the output neuron through directed edges, which can have either
                positive or negative weights. Positive weights are associated with excitatory nodes, while negative
                weights are associated with inhibitory nodes.</p>

            <h3>Activation Function and Threshold Value</h3>
            <p>The firing of the output neuron depends on a threshold value. The activation function of this network can
                be defined as follows:</p>
            <p>Let \(F(y_n)\) be the activation function, where \(y_n\) is the net input. The function can be expressed
                as:</p>
            <p>
                \(F(y_n) = \begin{cases} 1 & \text{if } y_n \geq &theta; \\ 0 & \text{otherwise} \end{cases}\)
            </p>
            <p>Here, &theta; is the threshold value. For the neuron to fire, the net input \(y_n\) must be greater
                than or equal to the threshold value.</p>


            <h3>Determining the Threshold Value</h3>
            <p>The value of &theta; should be greater than \(n \cdot W - P\), where:</p>
            <ul>
                <li>\(n\) = Number of neurons in the input layer</li>
                <li>\(W\) = Positive weight</li>
                <li>\(P\) = Negative weight</li>
            </ul>
            <div class="in">
                <h3>AND Function Implementation Using McCulloch-Pitts Neuron</h3>

                <p><strong>1. Truth Table of AND Function</strong></p>
                <p>The truth table for the AND function clearly illustrates the relationship between the inputs and the
                    output. In the context of logic gates, an AND gate outputs a high signal (1) only when all its
                    inputs are high. This behavior is fundamental in digital electronics and can be represented as
                    follows:</p>
                <pre>
                    <code>
+---------+---------+--------+
| Input X1| Input X2| Output |
+---------+---------+--------+
|    0    |    0    |   0    |
|    0    |    1    |   0    |
|    1    |    0    |   0    |
|    1    |    1    |   1    |
+---------+---------+--------+
                    </code>
                </pre>
                <p>From the truth table, it is evident that the output is high only when both inputs are high (1). If
                    either input is low (0), the output is also low (0). This binary relationship forms the basis of how
                    the McCulloch-Pitts neuron will function in this scenario.</p>

                <p><strong>2. Understanding Weights and Threshold</strong></p>
                <p>One crucial aspect to note is that the McCulloch-Pitts neuron does not utilize a built-in training
                    algorithm like modern neural networks. Instead, we must manually analyze the input combinations to
                    determine the optimal weights and threshold values required for the desired output behavior.</p>
                <p>For implementing the AND function, we can assume the following weights for our inputs:</p>
                <ul>
                    <li>\(W_1 = 1\)</li>
                    <li>\(W_2 = 1\)</li>
                </ul>
                <p>These weights represent the contribution of each input to the net input of the neuron. With these
                    assumptions in place, we can now calculate the net input at the output neuron based on various input
                    combinations:</p>

                <p><strong>Net Input Calculations</strong></p>
                <p>Let’s compute the net input \(y_n\) for each possible combination of inputs:</p>
                <p>1. For inputs \(X_1 = 1\) and \(X_2 = 1\):</p>
                <p>
                    \(y_n = (X_1 \cdot W_1) + (X_2 \cdot W_2) = (1 \cdot 1) + (1 \cdot 1) = 2\)
                </p>
                <p>In this scenario, both inputs are high, resulting in a net input of 2.</p>

                <p>2. For inputs \(X_1 = 1\) and \(X_2 = 0\):</p>
                <p>
                    \(y_n = (1 \cdot 1) + (0 \cdot 1) = 1\)
                </p>
                <p>Here, the first input is high while the second is low, yielding a net input of 1.</p>

                <p>3. For inputs \(X_1 = 0\) and \(X_2 = 1\):</p>
                <p>
                    \(y_n = (0 \cdot 1) + (1 \cdot 1) = 1\)
                </p>
                <p>Similar to the previous case, only one input is high, resulting in a net input of 1.</p>

                <p>4. For inputs \(X_1 = 0\) and \(X_2 = 0\):</p>
                <p>
                    \(y_n = (0 \cdot 1) + (0 \cdot 1) = 0\)
                </p>
                <p>Both inputs being low produces a net input of 0, indicating that the neuron does not fire.</p>

                <p><strong>3. Determining the Threshold Value</strong></p>
                <p>To ensure that the McCulloch-Pitts neuron fires (outputs 1) only when both inputs are high (1), we
                    need to establish an appropriate threshold value, denoted as \(\theta\). Based on our previous
                    calculations, we can conclude:</p>
                <ul>
                    <li>If \(\theta \geq 2\), the neuron will fire when both inputs are high (1).</li>
                    <li>If \(\theta < 2\), the neuron will not fire in cases where either input is low (0).</li>
                </ul>
                <p>Thus, we determine that the threshold value \(\theta\) should be set to 2 to achieve the desired
                    behavior of the AND function.</p>

                <p>Additionally, we can calculate the threshold value using the following equation:</p>
                <p>
                    \(\theta \geq n \cdot W - P\)
                </p>
                <p>Where:</p>
                <ul>
                    <li>\(n\) is the number of neurons in the input layer (in this case, \(n = 2\)).</li>
                    <li>\(W\) is the positive weight (here, \(W = 1\)).</li>
                    <li>\(P\) is the negative weight, which in this case is \(0\) since we do not have inhibitory
                        inputs.</li>
                </ul>
                <p>Substituting these values into the equation gives:</p>
                <p>
                    \(\theta \geq 2 \cdot 1 - 0 = 2\)
                </p>
                <p>Thus, both methods confirm that the threshold value should be set to 2.</p>

                <p><strong>4. Final Activation Function</strong></p>
                <p>The final activation function for the McCulloch-Pitts neuron can be expressed mathematically as:</p>
                <p>
                    \(F(y_n) = \begin{cases}
                    1 & \text{if } y_n \geq 2 \\
                    0 & \text{otherwise}
                    \end{cases}\)
                </p>
                <p>This function confirms that the neuron will fire (output 1) only when both inputs \(X_1\) and \(X_2\)
                    are equal to 1, effectively implementing the AND logical function. The simplicity of the
                    McCulloch-Pitts model highlights its significance as a foundational concept in neural network
                    theory, paving the way for more complex learning algorithms and structures in modern artificial
                    intelligence.</p>
            </div>
            <!-- <div class="in">
                <h3>ANDNOT Function Implementation Using McCulloch-Pitts Neuron</h3>

                <p><strong>1. Truth Table of ANDNOT Function</strong></p>
                <p>The truth table for the ANDNOT function clearly illustrates the relationship between the inputs and
                    the output. In this case, we have two inputs: \(X_1\) and \(X_2\), and \(Y\) is the output. The
                    ANDNOT function outputs a high signal (1) only when \(X_1\) is high (1) and \(X_2\) is low (0). This
                    behavior can be represented as follows:</p>
                <pre>
                    <code>
+---------+---------+--------+
| Input X1| Input X2| Output |
+---------+---------+--------+
|    0    |    0    |   0    |
|    0    |    1    |   0    |
|    1    |    0    |   1    |
|    1    |    1    |   0    |
+---------+---------+--------+
                    </code>
                </pre>
                <p>From the truth table, it is evident that the output is high only when \(X_1\) is high (1) and \(X_2\)
                    is low (0). In all other cases, the output is low (0). This binary relationship forms the basis of
                    how the McCulloch-Pitts neuron will function in this scenario.</p>

                <p><strong>2. Understanding Weights and Threshold</strong></p>
                <p>One crucial aspect to note is that the McCulloch-Pitts neuron does not utilize a built-in training
                    algorithm. Therefore, we need to analyze the input combinations to determine the optimal weights and
                    threshold values required for the desired output behavior.</p>
                <p>For implementing the ANDNOT function, we can assume the following weights for our inputs:</p>
                <ul>
                    <li>\(W_1 = 1\)</li>
                    <li>\(W_2 = -1\)</li>
                </ul>
                <p>These weights indicate that the first input contributes positively to the net input, while the second
                    input contributes negatively. With these assumptions in place, we can now calculate the net input at
                    the output neuron based on various input combinations:</p>

                <p><strong>Net Input Calculations</strong></p>
                <p>Let’s compute the net input \(y_n\) for each possible combination of inputs:</p>
                <p>1. For inputs \(X_1 = 1\) and \(X_2 = 1\):</p>
                <p>
                    \(y_n = (X_1 \cdot W_1) + (X_2 \cdot W_2) = (1 \cdot 1) + (1 \cdot -1) = 0\)
                </p>
                <p>In this scenario, both inputs are high, resulting in a net input of 0.</p>

                <p>2. For inputs \(X_1 = 1\) and \(X_2 = 0\):</p>
                <p>
                    \(y_n = (1 \cdot 1) + (0 \cdot -1) = 1\)
                </p>
                <p>Here, the first input is high while the second is low, yielding a net input of 1.</p>

                <p>3. For inputs \(X_1 = 0\) and \(X_2 = 1\):</p>
                <p>
                    \(y_n = (0 \cdot 1) + (1 \cdot -1) = -1\)
                </p>
                <p>In this case, only the second input is high, resulting in a negative net input of -1.</p>

                <p>4. For inputs \(X_1 = 0\) and \(X_2 = 0\):</p>
                <p>
                    \(y_n = (0 \cdot 1) + (0 \cdot -1) = 0\)
                </p>
                <p>Both inputs being low produces a net input of 0, indicating that the neuron does not fire.</p>

                <p><strong>3. Determining the Threshold Value</strong></p>
                <p>To ensure that the McCulloch-Pitts neuron fires (outputs 1) only when \(X_1\) is high (1) and \(X_2\)
                    is low (0), we need to establish an appropriate threshold value, denoted as \(\theta\). Based on our
                    previous calculations, we can conclude:</p>
                <ul>
                    <li>If \(\theta \leq 1\), the neuron will fire when \(X_1\) is 1 and \(X_2\) is 0.</li>
                    <li>If \(\theta > 1\), the neuron will not fire in cases where \(X_2\) is high (1).</li>
                </ul>
                <p>Thus, we determine that the threshold value \(\theta\) should be set to 1 to achieve the desired
                    behavior of the ANDNOT function.</p>

                <p>Additionally, we can calculate the threshold value using the following equation:</p>
                <p>
                    \(\theta \geq n \cdot W - P\)
                </p>
                <p>Where:</p>
                <ul>
                    <li>\(n\) is the number of neurons in the input layer (in this case, \(n = 2\)).</li>
                    <li>\(W\) is the positive weight (here, \(W = 1\)).</li>
                    <li>\(P\) is the negative weight (in this case, \(P = 1\)).</li>
                </ul>
                <p>Substituting these values into the equation gives:</p>
                <p>
                    \(\theta \geq 2 \cdot 1 - 1 = 1\)
                </p>
                <p>Thus, both methods confirm that the threshold value should be set to 1.</p>

                <p><strong>4. Final Activation Function</strong></p>
                <p>The final activation function for the McCulloch-Pitts neuron can be expressed mathematically as:</p>
                <p>
                    \(F(y_n) = \begin{cases}
                    1 & \text{if } y_n \geq 1 \\
                    0 & \text{otherwise}
                    \end{cases}\)
                </p>
                <p>This function confirms that the neuron will fire (output 1) only when \(X_1\) is equal to 1 and
                    \(X_2\) is equal to 0, effectively implementing the ANDNOT logical function. The simplicity of the
                    McCulloch-Pitts model highlights its significance as a foundational concept in neural network
                    theory, paving the way for more complex learning algorithms and structures in modern artificial
                    intelligence.</p>
            </div> -->
            <div class="in">
                <h3>XOR Function Implementation Using McCulloch-Pitts Neuron</h3>

                <p><strong>1. Truth Table of XOR Function</strong></p>
                <p>The truth table for the XOR function demonstrates how the outputs are determined based on the inputs.
                    In this case, we have two inputs: \(X_1\) and \(X_2\), and \(Y\) is the output. The XOR function
                    outputs a high signal (1) only when the inputs are different (one high and one low). This behavior
                    can be represented as follows:</p>
                <pre>
                    <code>
+---------+---------+--------+
| Input X1| Input X2| Output |
+---------+---------+--------+
|    0    |    0    |   0    |
|    0    |    1    |   1    |
|    1    |    0    |   1    |
|    1    |    1    |   0    |
+---------+---------+--------+
                    </code>
                </pre>
                <p>From the truth table, we observe that the output is high (1) when one of the inputs is high and the
                    other is low, while it is low (0) when both inputs are the same. This binary relationship
                    establishes the foundation for how the McCulloch-Pitts neuron will function for the XOR operation.
                </p>

                <p><strong>2. Understanding Weights and Threshold</strong></p>
                <p>It is essential to note that the McCulloch-Pitts neuron does not utilize a built-in training
                    algorithm. Therefore, we need to analyze the input combinations to determine the appropriate weights
                    and threshold values required for the desired output behavior.</p>
                <p>For implementing the XOR function, we can assume the following weights for our inputs:</p>
                <ul>
                    <li>\(W_1 = 1\)</li>
                    <li>\(W_2 = 1\)</li>
                    <li>\(W_3 = -2\) (for a simulated bias)</li>
                </ul>
                <p>These weights suggest that both inputs contribute positively to the net input, while the bias acts to
                    reduce the output when both inputs are high. With these assumptions, we can calculate the net input
                    at the output neuron based on various input combinations:</p>

                <p><strong>Net Input Calculations</strong></p>
                <p>Let’s compute the net input \(y_n\) for each possible combination of inputs:</p>
                <p>1. For inputs \(X_1 = 0\) and \(X_2 = 0\):</p>
                <p>
                    \(y_n = (X_1 \cdot W_1) + (X_2 \cdot W_2) + W_3 = (0 \cdot 1) + (0 \cdot 1) + (-2) = -2\)
                </p>
                <p>In this scenario, both inputs are low, resulting in a net input of -2.</p>

                <p>2. For inputs \(X_1 = 0\) and \(X_2 = 1\):</p>
                <p>
                    \(y_n = (0 \cdot 1) + (1 \cdot 1) + (-2) = -1\)
                </p>
                <p>Here, the second input is high while the first is low, yielding a net input of -1.</p>

                <p>3. For inputs \(X_1 = 1\) and \(X_2 = 0\):</p>
                <p>
                    \(y_n = (1 \cdot 1) + (0 \cdot 1) + (-2) = -1\)
                </p>
                <p>In this case, the first input is high while the second is low, resulting in a net input of -1.</p>

                <p>4. For inputs \(X_1 = 1\) and \(X_2 = 1\):</p>
                <p>
                    \(y_n = (1 \cdot 1) + (1 \cdot 1) + (-2) = 0\)
                </p>
                <p>Both inputs being high produces a net input of 0, indicating that the neuron does not fire.</p>

                <p><strong>3. Determining the Threshold Value</strong></p>
                <p>To ensure that the McCulloch-Pitts neuron fires (outputs 1) only when the inputs are different, we
                    need to establish an appropriate threshold value, denoted as \(\theta\). Based on our previous
                    calculations, we can conclude:</p>
                <ul>
                    <li>If \(\theta \leq 0\), the neuron will fire when one of the inputs is 1 and the other is 0.</li>
                    <li>If \(\theta > 0\), the neuron will not fire when both inputs are high (1).</li>
                </ul>
                <p>Thus, we determine that the threshold value \(\theta\) should be set to 0 to achieve the desired
                    behavior of the XOR function.</p>

                <p>Additionally, we can calculate the threshold value using the following equation:</p>
                <p>
                    \(\theta \geq n \cdot W - P\)
                </p>
                <p>Where:</p>
                <ul>
                    <li>\(n\) is the number of neurons in the input layer (in this case, \(n = 2\)).</li>
                    <li>\(W\) is the positive weight (here, \(W = 1\)).</li>
                    <li>\(P\) is the negative weight (in this case, \(P = 2\)).</li>
                </ul>
                <p>Substituting these values into the equation gives:</p>
                <p>
                    \(\theta \geq 2 \cdot 1 - 2 = 0\)
                </p>
                <p>Thus, both methods confirm that the threshold value should be set to 0.</p>

                <p><strong>4. Final Activation Function</strong></p>
                <p>The final activation function for the McCulloch-Pitts neuron can be expressed mathematically as:</p>
                <p>
                    \(F(y_n) = \begin{cases}
                    1 & \text{if } y_n \geq 0 \\
                    0 & \text{otherwise}
                    \end{cases}\)
                </p>
                <p>This function confirms that the neuron will fire (output 1) only when the inputs differ, effectively
                    implementing the XOR logical function. The XOR function serves as a critical example in neural
                    network theory, showcasing the limitations of simple models and paving the way for more advanced
                    learning algorithms and structures in artificial intelligence.</p>
            </div>
        </div>
        <div class="wh">
            <h2>Hebb Network / Hebbian Rule</h2>
            <p><strong>1. Introduction to Hebbian Rule</strong></p>
            <p>The Hebbian Rule is one of the simplest learning rules under artificial neural networks. It was
                introduced in 1949 by Donald Hebb. According to Hebb, learning in the brain occurs due to changes in the
                synaptic gap, which can be attributed to metabolic changes or growth. This rule is based on the
                biological processes that occur in the brain during learning.</p>
            <p>To understand the Hebbian Rule, let’s first consider the structure of a biological neuron. Each neuron
                has three main parts:</p>
            <ul>
                <li><strong>Cell Body (Soma):</strong> This is where the nucleus is located.</li>
                <li><strong>Axon:</strong> A long connection extending from one neuron to another.</li>
                <li><strong>Dendrites:</strong> Small nerves connected to the cell body that transmit electrical
                    impulses.</li>
            </ul>
            <p>The electrical impulses are passed from one neuron to another through synapses, which are small gaps
                between neurons. When learning occurs, metabolic changes happen in the synaptic gap, leading to the
                formation of new connections between neurons.</p>

            <p><strong>2. Hebbian Rule Definition</strong></p>
            <p>Donald Hebb's definition of the Hebbian Rule is as follows:</p>
            <blockquote>
                "When an axon of cell A is near enough to excite cell B and repeatedly or persistently fires it, some
                growth process or metabolic change takes place in one or both cells."
            </blockquote>
            <p>In simpler terms, if neuron A excites neuron B frequently, changes occur in their synaptic gap, which
                strengthens the connection between the two neurons.</p>

            <p>Hebb's Rule was inspired by the way learning happens in the human brain. A relatable example of this can
                be seen when learning to drive. Initially, when you start driving, you are conscious of every action,
                like turning or reversing. However, over time, as it becomes a habit, you can drive effortlessly while
                doing other tasks, like listening to music. This example demonstrates how neurons become trained and
                perform tasks automatically over time, which is the core idea of Hebb’s learning theory.</p>

            <p><strong>3. Principles of Hebbian Rule</strong></p>
            <p>The Hebbian Rule follows two basic principles:</p>
            <ol>
                <li>If two neurons on either side of a connection are activated synchronously (both are on), the weight
                    between them is increased.</li>
                <li>If two neurons on either side of a connection are activated asynchronously (one is on, the other is
                    off), the weight between them is decreased.</li>
            </ol>

            <p><strong>4. Hebbian Rule Formula</strong></p>
            <p>According to Hebb's learning rule, when two interconnected neurons are activated simultaneously, the
                weights between them increase. The change in weight is represented by the following formula:</p>
            <pre>
                <code>
    W<sub>new</sub> = W<sub>old</sub> + ΔW
    ΔW = x<sub>i</sub> * y
                </code>
            </pre>
            <p>Where:</p>
            <ul>
                <li><strong>W<sub>new</sub>:</strong> New weight after learning</li>
                <li><strong>W<sub>old</sub>:</strong> Initial weight</li>
                <li><strong>ΔW:</strong> Change in weight (synaptic gap change)</li>
                <li><strong>x<sub>i</sub>:</strong> Input vector</li>
                <li><strong>y:</strong> Output vector</li>
            </ul>

            <p>This formula shows that changes in the synaptic gap lead to changes in the weights, allowing the neuron
                network to learn and adjust over time.</p>

            <p><strong>5. Flowchart of Hebbian Network</strong></p>
            <p>The flowchart of Hebbian learning involves several key steps:</p>
            <ol>
                <li><strong>Initialize weights:</strong> Weights are either set to zero or initialized with random
                    values.</li>
                <li><strong>For each input-output pair:</strong> Perform the following steps:</li>
                <ul>
                    <li>Activate the input unit: \(x_i = s_i\)</li>
                    <li>Activate the output unit: \(y = T\)</li>
                    <li>Update the weights using the Hebbian formula: \(W_i^{new} = W_i^{old} + x_i \times y\)</li>
                    <li>Update the bias: \(B^{new} = B^{old} + y\)</li>
                </ul>
                <li>If no more input-output pairs are available, stop the process.</li>
            </ol>
            <p>This flowchart represents how the Hebbian Network processes input and output pairs and adjusts weights
                based on learning.</p>

            <p><strong>6. Training Algorithm for Hebbian Network</strong></p>
            <p>The training algorithm for the Hebbian Network follows these steps:</p>
            <ol>
                <li><strong>Initialize the weights and bias:</strong> Set the weights and bias to either zero or random
                    values.</li>
                <li><strong>For each input-output pair:</strong> Perform the following:</li>
                <ul>
                    <li>Set the activation for the input unit: \(x_i = s_i\)</li>
                    <li>Set the activation for the output unit: \(y = T\)</li>
                    <li>Update the weights and bias using the formulas:</li>
                    <pre>
                        <code>
    W<sub>new</sub> = W<sub>old</sub> + x<sub>i</sub> * y
    B<sub>new</sub> = B<sub>old</sub> + y
                        </code>
                    </pre>
                </ul>
                <li>Repeat the process until there are no more input-output pairs.</li>
            </ol>

            <p>This training algorithm allows the Hebbian Network to learn and update its weights and bias, forming the
                basis for unsupervised learning in neural networks.</p>

            <p><strong>7. Applications of Hebbian Rule</strong></p>
            <p>The Hebbian learning rule is widely used in various applications, including:</p>
            <ul>
                <li><strong>Pattern Association:</strong> Associating different patterns based on inputs.</li>
                <li><strong>Pattern Categorization:</strong> Categorizing inputs based on learned patterns.</li>
                <li><strong>Pattern Classification:</strong> Classifying new inputs based on previously learned
                    patterns.</li>
            </ul>

            <p>In conclusion, Hebb's rule and network play a foundational role in understanding how neurons learn and
                adapt. The rule is simple yet powerful, forming the basis for more complex neural network models in
                artificial intelligence.</p>
            <div class="in">
                <h3>Hebbian Network for Logical AND Function (Bipolar Inputs)</h3>

                <p>We are tasked with designing a Hebbian network to implement the logical AND function using bipolar
                    inputs (1 or -1) and targets. The truth table for the AND function is as follows:</p>

                <p><strong>Truth Table</strong></p>
                <pre>
                    <code>
Inputs (X1, X2) and Target (Y)
+----+----+----+
| X1 | X2 | Y  |
+----+----+----+
|  1 |  1 |  1 |
|  1 | -1 | -1 |
| -1 |  1 | -1 |
| -1 | -1 | -1 |
+----+----+----+
                    </code>
                </pre>

                <p>We will initialize the weights (W1, W2) and bias (B) to zero and use the Hebbian learning rule to
                    update the weights based on the input-output pairs.</p>

                <p><strong>Weight Update Rule</strong></p>
                <p>The weight and bias update rules in Hebbian learning are as follows:</p>

                <pre>
                    <code>
W1(new) = W1(old) + X1 * Y
W2(new) = W2(old) + X2 * Y
B(new)  = B(old) + Y
                    </code>           
                </pre>

                <p><strong>Step-by-Step Calculation</strong></p>

                <pre>
                    <code>
Initial Weights: W1 = 0, W2 = 0, B = 0
+----+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+
| X1 | X2 |  Y |  B | W1  | W2  | ΔW1 | ΔW2 | ΔB  | W1  | w2  |  B  |
|    |    |    |    | old | old |     |     |     | new | new | new |
+----+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+
|  1 |  1 |  1 |  1 |  0  |  0  |  1  |  1  |  1  |  1  |  1  |  1  |
|  1 | -1 | -1 |  1 |  1  |  1  | -1  |  1  | -1  |  0  |  2  |  0  |
| -1 |  1 | -1 |  1 |  0  |  2  |  1  | -1  | -1  |  1  |  1  | -1  |
| -1 | -1 | -1 |  1 |  1  |  1  |  1  |  1  | -1  |  2  |  2  | -2  |
+----+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+
Final Weights: W1 = 2, W2 = 2, B = -2
                    </code>
                </pre>

                <p><strong>Final Solution Check</strong></p>

                <p>Now, we check whether the final weights produce the correct output for the AND function. The formula
                    is:</p>

                <p>
                    Y = B + X1 * W1 + X2 * W2
                </p>

                <p>Substituting the final weights for the first set of inputs (X1 = 1, X2 = 1):</p>

                <p>
                    Y = -2 + 1 * 2 + 1 * 2 = -2 + 2 + 2 = 2 (positive value, correct output)
                </p>

                <p>Since we get the correct output for the AND function, the final weights are correct.</p>

                <p>This approach can be applied to other logical functions such as OR, NOT, NAND, etc., by adjusting the
                    truth table and applying the Hebbian learning process.</p>
            </div>
        </div>
        <div class="wh">
            <h2>Perceptron Learning Rule</h2>
            <p>The Perceptron Learning Rule is an algorithm used to train a single-layer perceptron. The perceptron is a
                simple binary classifier that decides the output based on the weighted sum of the inputs and a bias,
                followed by an activation function. The learning rule adjusts the weights and bias to reduce
                classification errors.</p>

            <h3>Key Components of the Perceptron</h3>
            <ul>
                <li><strong>Weights (W):</strong> The strength of the connection between input neurons and the output
                    neuron. Initialized randomly or to zero.</li>
                <li><strong>Bias (B):</strong> An additional input that helps to shift the activation threshold of the
                    neuron.</li>
                <li><strong>Net Input (y_input):</strong> The sum of the weighted inputs and the bias. Calculated as:
                    <br>
\(
y_{\text{input}} = B + \sum_{i} (x_i \cdot W_i)
\)
                </li>
                <li><strong>Activation Function:</strong> A function that determines the final output of the perceptron.
                    The most common one is the step function, used for binary classification.</li>
            </ul>

            <h3>Step Activation Function</h3>
            <p>The step function is used to decide the perceptron's output based on the net input:</p>
            <ul>
                <li><strong>1</strong> if the net input is ≥ 0 (positive).</li>
                <li><strong>-1</strong> if the net input is &lt; 0 (negative).</li>
            </ul>
            <p>Mathematically:
                <br>\(
                f(y_{\text{input}}) =
                \begin{cases}
                1 & \text{if } y_{\text{input}} \geq 0 \\
                -1 & \text{if } y_{\text{input}} < 0 \end{cases} \) </p>

                    <h3>Weight Update Rule (Learning Rule)</h3>
                    <p>During training, the perceptron's weights and bias are updated based on the difference between
                        the target output and the perceptron’s predicted output. The update rules are:
                        <br>\(
                        \Delta W_i = \alpha \cdot (T - y) \cdot x_i
                        \)
                        <br>\(
                        \Delta B = \alpha \cdot (T - y)
                        \)
                    </p>
                    <ul>
                        <li><strong>Alpha (α):</strong> Learning rate (between 0 and 1).</li>
                        <li><strong>T:</strong> The target output (desired output).</li>
                        <li><strong>y:</strong> The actual output of the perceptron.</li>
                        <li><strong>x_i:</strong> The input value.</li>
                    </ul>

                    <h3>Steps for Perceptron Training</h3>
                    <ol>
                        <li><strong>Initialize weights and bias:</strong> Set all weights and bias to zero or small
                            random values.</li>
                        <li><strong>For each training example:</strong>
                            <ul>
                                <li>Compute the net input.</li>
                                <li>Apply the activation function to get the output.</li>
                                <li>Update the weights and bias if the output does not match the target.</li>
                            </ul>
                        </li>
                        <li><strong>Repeat:</strong> Continue the process for multiple iterations until the perceptron
                            correctly classifies all training examples or the error is sufficiently minimized.</li>
                    </ol>
        </div>
        <div class="wh">
            <h2>Perceptron Neural Network</h2>
            <p><strong>Perceptron Neural Network</strong> is a foundational model in the field of <strong>Artificial
                    Neural Networks (ANNs)</strong>, operating under the paradigm of <strong>supervised
                    learning</strong>. Supervised learning refers to a process where the model is trained using labeled
                data, meaning both input values and their corresponding target (output) values are provided during
                training. The Perceptron is widely regarded as one of the simplest forms of neural networks, primarily
                designed for tasks such as binary classification, where it can classify input data into two distinct
                categories. Despite its simplicity, the Perceptron plays a crucial role as a <strong>building
                    block</strong> in the development of more advanced neural networks, serving as an early stepping
                stone in the evolution of machine learning models.</p>

            <h3>Architecture of Perceptron Neural Network</h3>
            <img src="../../images/sc7.jpeg" alt="">
            <p>The architecture consists of four main components:</p>
            <ul>
                <li><strong>Inputs</strong>: Inputs are the data provided to the neural network. For instance, if there
                    are four inputs, then the
                    network will have four input nodes.</li>
                <li><strong>Weights and Bias</strong>: The weights and bias are values between the input and output
                    layers. The weights control the strength of
                    the connection between input and output, and the values typically range between 0 and 1.</li>
                <li><strong>Net Input Function</strong>: The net input function is calculated by multiplying the input
                    values with the respective weights, and
                    then summing the result. The formula is:
                    <br>X1 * W1 + X2 * W2 + ... + Xm * Wm + B
                </li>
                <li><strong>Activation Function</strong>: After calculating the net input, an <strong>activation
                        function</strong> is applied to determine whether
                    the neuron will "fire" (produce an output). The perceptron typically uses the <strong>Step
                        Activation
                        Function</strong>, which outputs:
                    <ul>
                        <li><strong>1</strong> if the net input is greater than a certain threshold value</li>
                        <li><strong>0</strong> if the net input is between a negative and positive threshold</li>
                        <li><strong>-1</strong> if the net input is less than the negative threshold</li>
                    </ul>
                </li>
            </ul>


            <h3>Working of Perceptron</h3>
            <p>The perceptron operates by comparing the output of the activation function with the target output. If
                there is a mismatch, the network adjusts the weights and repeats the process until the error is
                minimized or eliminated.</p>

            <h3>Perceptron Types</h3>
            <ul>
                <li><strong>Single-Layer Perceptron</strong>: Consists of only one layer of nodes.</li>
                <li><strong>Multi-Layer Perceptron</strong>: Contains two or more layers, allowing for greater
                    processing capability.</li>
            </ul>

            <h3>Mathematical Formula for Perceptron</h3>
            <p>The general formula to calculate the output (Y) is: <br>
                Y = f(X1 * W1 + X2 * W2 + ... + Xm * Wm + B)</p>



            <p>Where <strong>f</strong> is the activation function. In the step activation function:
                <br>\(
                f(y) =
                \begin{cases}
                1 & \text{if } y > \text{threshold} \\
                0 & \text{if } -\text{threshold} \leq y \leq +\text{threshold} \\
                -1 & \text{if } y < -\text{threshold} \end{cases} \)</p>


                    <h3>Weight Updation</h3>
                    <p>When an error occurs, the weights are updated using the formula:
                        <br>New Weight = Old Weight + Alpha * T * X
                    </p>
                    <p>Where:</p>
                    <ul>
                        <li><strong>Alpha</strong>: Learning rate (between 0 and 1)</li>
                        <li><strong>T</strong>: Target value</li>
                        <li><strong>X</strong>: Input value</li>
                    </ul>

                    <h3>Perceptron Training Algorithm</h3>
                    <p>The training algorithm follows these steps:</p>
                    <ol>
                        <li><strong>Initialize weights</strong> and bias, and set the learning rate (Alpha).</li>
                        <li>For each training input pair, calculate the <strong>net input</strong>:
                            <br>Y_input = X1 * W1 + X2 * W2 + ... + Xn * Wn + B
                        </li>
                        <li>Apply the <strong>activation function</strong> and calculate the output (Y).</li>
                        <li><strong>Compare</strong> the output (Y) with the target value (T). If they are equal,
                            proceed. If
                            not, update the weights using the formula.</li>
                        <li>Repeat this process until there are no further inputs or the error becomes zero.</li>
                    </ol>

                    <h3>Flowchart of Perceptron Training</h3>
                    <p>The flowchart of the perceptron training process involves:</p>
                    <ol>
                        <li>Initializing the weights and bias.</li>
                        <li>Calculating the net input and applying the activation function.</li>
                        <li>Comparing the output with the target value.</li>
                        <li>Updating the weights if necessary.</li>
                        <li>Repeating the process until the output matches the target.</li>
                    </ol>

                    <h3>Testing Algorithm</h3>
                    <p>After training, the network is tested using the following steps:</p>
                    <ol>
                        <li><strong>Step 0</strong>: Use the weights obtained from the training phase.</li>
                        <li><strong>Step 1</strong>: For each test input pair, calculate the net input using the same
                            formula:
                            <br>Y_input = X1 * W1 + X2 * W2 + ... + Xn * Wn + B
                        </li>
                        <li><strong>Step 2</strong>: Apply the activation function and compare the output with the
                            target value.
                            If they match, the weights are considered correct.</li>
                    </ol>
                    <div class="in">
                        <h3>Perceptron Network Implementation for AND Function</h3>

                        <p><strong>Step 1: Initialize Weights and Bias</strong></p>

                        <p>
                            Weights (W1, W2) = 0
                            <br>
                            Bias (B) = 0
                        </p>

                        <p><strong>Step 2: Calculate Net Input (y_input)</strong></p>

                        <p>
                            y_input = B + Σ(x_i * W_i) <br>
                            Apply activation function: <br>\( f(y\_input) =
                            \begin{cases}
                            1 & \text{if } y\_input > 0 \\
                            0 & \text{if } y\_input = 0 \\
                            -1 & \text{if } y\_input < 0 \end{cases} \) </p>

                                <p><strong>Step 3: Update Weights and Bias</strong></p>

                                <p>
                                    If y ≠ target, update weights and bias using the formula:<br>
                                    ΔW_i = α * T * x_i (α = 1)<br>
                                    ΔB = α * T<br>
                                    New weights = old weights + ΔW_i<br>
                                    New bias = old bias + ΔB
                                </p>

                                <p><strong>Truth Table for AND Function</strong></p>

                                <pre>
    <code>
+----+----+--------+
| X1 | X2 | Target |
+----+----+--------+
|  1 |  1 |    1   |
|  1 | -1 |   -1   |
| -1 |  1 |   -1   |
| -1 | -1 |   -1   |
+----+----+--------+
    </code>
</pre>

                                <p><strong>First Approach</strong></p>

                                <pre>
    <code>
+----+----+-------+--------+---------+-----+-----+-----+-----+-----+-----+-----+
| X1 | X2 |   b   | Target | y_input |  y  | ΔW1 | ΔW2 | ΔB  | W1  | W2  |  B  |
|    |    | input |        |         |     |     |     |     | new | new | new |
+----+----+-------+--------+---------+-----+-----+-----+-----+-----+-----+-----+
|  1 |  1 |   1   |   1    |    0    |  0  |  1  |  1  |  1  |  1  |  1  |  1  |
|  1 | -1 |   1   |  -1    |    1    |  1  | -1  |  1  | -1  |  0  |  2  |  0  |
| -1 |  1 |   1   |  -1    |    2    |  1  |  1  | -1  | -1  |  1  |  1  | -1  |
| -1 | -1 |   1   |  -1    |   -3    | -1  |  0  |  0  |  0  |  1  |  1  | -1  |
+----+----+-------+--------+---------+-----+-----+-----+-----+-----+-----+-----+
Final Weights: W1 = 1, W2 = 1, B = -1
    </code>
</pre>

                                <p><strong>Second Approach</strong></p>

                                <pre>
    <code>
+----+----+-------+--------+---------+-----+-----+-----+-----+-----+-----+-----+
| X1 | X2 |   b   | Target | y_input |  y  | ΔW1 | ΔW2 | ΔB  | W1  | W2  |  B  |
|    |    | input |        |         |     |     |     |     | new | new | new |
+----+----+-------+--------+---------+-----+-----+-----+-----+-----+-----+-----+
|  1 |  1 |  -1   |    1   |    1    |  1  |  0  |  0  |  0  |  1  |  1  | -1  |
|  1 | -1 |  -1   |   -1   |   -1    | -1  |  0  |  0  |  0  |  1  |  1  | -1  |
| -1 |  1 |  -1   |   -1   |   -1    | -1  |  0  |  0  |  0  |  1  |  1  | -1  |
| -1 | -1 |  -1   |   -1   |   -3    | -1  |  0  |  0  |  0  |  1  |  1  | -1  |
+----+----+-------+--------+---------+-----+-----+-----+-----+-----+-----+-----+
Final Weights: W1 = 1, W2 = 1, B = -1
    </code>
</pre>

                                <p><strong>Final Weights</strong></p>

                                <p>
                                    W1 = 1<br>
                                    W2 = 1<br>
                                    B = -1
                                </p>

                                <p><strong>Verification</strong></p>

                                <p>
                                    For input (1, 1), y_input = 1, y = 1 (correct) <br>
                                    For input (1, -1), y_input = -1, y = -1 (correct)<br>
                                    For input (-1, 1), y_input = -1, y = -1 (correct)<br>
                                    For input (-1, -1), y_input = -3, y = -1 (correct)
                                </p>
                    </div>
        </div>
        <div class="wh">
            <h2>Delta Learning Rule / Widrow-Hoff Rule</h2>
            <ul>
                <li>
                    The Widrow-Hoff rule is a supervised learning algorithm. Supervised learning involves a process
                    where the desired output is compared with the actual output. The difference between the two (error)
                    is used to adjust the weights. This process is repeated iteratively until the actual output is close
                    to the desired output.
                </li>
                <li>
                    The algorithm uses the difference between the actual output of the neuron and the desired output as
                    the error signal for units in the output layer.
                </li>
                <li>
                    In Widrow-Hoff learning, the correction to the synaptic weight is proportional to the error signal
                    multiplied by the activation value, which is determined by the derivative of the transfer function.
                </li>
                <li>
                    <b>Weight adjustment formula:</b>
                    <br>&Delta;w<sub>new</sub> = &alpha;(t - y<sub>in</sub>) * x<sub>i</sub> + &Delta;w<sub>old</sub>
                    <br><b>&alpha;</b> = learning rate: The learning rate controls how much the weights are adjusted in
                    each iteration. It is a small positive value that ensures gradual convergence.
                    <br><b>t</b> = target value: This is the desired output for a given input.
                    <br><b>y<sub>in</sub></b> = net input to the output unit: This is the weighted sum of inputs to the
                    neuron.
                    <br>y<sub>in</sub>: \( \sum_{i=1}^{n} x_i w_i \)
                </li>
                <li>
                    The delta rule is derived from gradient descent, meaning it tries to minimize the error by updating
                    the weights in the direction that reduces the error.
                </li>
                <li>
                    The perceptron learning rule stops after a finite number of steps, while the gradient descent
                    approach continues indefinitely, converging asymptotically to the solution.
                </li>
            </ul>
        </div>
    </div>
    <div class="wh">
        <p>Reference</p>
        <ul>
            <li><a href="https://youtu.be/dl8C8enkBwo?si=a-3Ro4qWb9g2i08T" target="_blank">Biological Neural Network
                    Video Lecture &neArr;</a></li>
            <li><a href="https://youtu.be/rnxZ2jaRABs?si=-nvaD7duk0kyc1UT" target="_blank">Activation Functions
                    &neArr;</a></li>
            <li><a href="https://youtu.be/fYBmBo_k5qg?si=YEGiypPLYJGBAsC5" target="_blank">Hebb Rule &neArr;</a>
            </li>
            <li><a href="https://www.youtube.com/watch?v=xqMCEFPk2cY" target="_blank">AND function using Hebb Rule &neArr;</a></li>
            <li><a href="https://youtu.be/_jwbyA5eqZg?si=m8D2TwWXWC6UNI8e" target="_blank">Perceptron &neArr;</a></li>
            <li><a href="https://www.youtube.com/watch?v=SWXOcipNST8" target="_blank">Delta Learning Rule &neArr;</a>
            </li>
        </ul>
    </div>
    <script src="../../../../public/main.js"></script>
</body>

</html>